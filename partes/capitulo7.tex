\chapter{Conclusiones}
\label{capitulo7}
\lhead{Capítulo 7. \emph{Conclusiones}}

En el capítulo anterior, se abordan los desafíos del ajuste fino de la política estudiante y se proporciona en detalle los resultados de la política de evasión de obstáculos, tanto en entornos de simulación como en entornos de la vida real. En el presente capítulo, se confirma el logro de los objetivos propuestos para este trabajo, se destacan lecciones aprendidas y se abordarán las limitaciones identificadas. Así mismo, se presentan sugerencias para futuras investigaciones que busquen aprovechar y mejorar la implementación de algoritmos para la evasión autónoma de obstáculos para QUAVs.

Con respecto al cumplimiento de los objetivos propuestos para este trabajo, se puede observar que: 

\begin{itemize}
\item{
    Se llevó a cabo una revisión del estado del arte de los algoritmos de evitación de obstáculos para drones autónomos, como se detalla en el Capítulo \ref{capitulo4}. La investigación se organizó clasificando los estudios relevantes según su dependencia y uso de información global, generando así una visión general del estado actual del campo, para poder evaluar e implementar un algoritmo adecuado a las necesidades de ACSL. Se profundizó específicamente en el trabajo titulado \textit{Learning high-speed flight in the wild} \cite{Loquercio2021} debido a sus características atractivas para el caso de implementación por parte de ACSL.
}

\item{
    Se implementó un algoritmo de evitación de obstáculos para drones autónomos en un entorno de simulación. El algoritmo seleccionado se basó en la metodología propuesta por Loquercio et al. (2021) \cite{Loquercio2021}, y los detalles de su implementación se presentan en el Capítulo \ref{capitulo5}. La evaluación de la implementación se llevó a cabo en el entorno de simulación AirSim \cite{shah2018airsim}, y los resultados de los vuelos realizados funcionan como base sólida para el desarrollo de nuevos proyectos e investigaciones, ya que se obtuvieron resultados positivos donde la política de evasión se mostró estable con configuraciones simples, además, se hicieron pruebas con distintos escenarios para evaluar las consecuencias que conllevan las variaciones, dichos resultados se describen de forma detallada en la Sección \ref{sec:results-AirSim}.
}

\item{
    Se trasladó la implementación realizada al hardware de un dron autónomo realizando las optimizaciones necesarias, y se realizaron de pruebas de campo de dicha implementación. Se empleó el dron SOTEN, un QUAV ligero diseñado y producido por ACSL para aplicaciones de vigilancia e inspección. Con el objetivo de reducir la carga computacional de la implementación, se introdujo un mecanismo que desactiva la inferencia de trayectorias cuando no hay obstáculos en el campo de visión del vehículo, según se detalla en el Algoritmo \ref{alg:nearest-depth} y en el Algoritmo \ref{alg:inference-loop}. Además, para posibilitar la ejecución en el hardware físico de SOTEN, se tradujo la representación del modelo de inferencia al estándar abierto para la interoperabilidad del aprendizaje de máquinas (ONNX). Finalmente, se llevaron a cabo pruebas en un entorno de la vida real  que mostraron resultados positivos para configuraciones de obstáculos simples; teniendo en cuenta las limitaciones de tiempo y las restricciones de la implementación, tal como se describe en la Sección \ref{sec:results-SOTEN}.
}
\end{itemize}

La consecución de cada uno de estos objetivos específicos valida y respalda el logro del objetivo general: implementar un algoritmo de evitación de obstáculos para drones autónomos y realizar pruebas tanto en un entorno de simulación como en el campo. Por lo tanto, se concluye que el presente trabajo cumplió satisfactoriamente con todos los objetivos propuestos.


Por otro lado, en relación a los resultados observados del algoritmo implementado, se destaca principalmente la marcada preferencia del algoritmo por esquivar obstáculos por el flanco izquierdo. Esta preferencia se atribuye a las dificultades encontradas durante el proceso de refinamiento fino de la política estudiante, específicamente al problema de sobre-ajuste generado por el desbalance en la generación de trayectorias con una velocidad de ejecución de 1 m/s para la base de datos de refinamiento fino. Debido a limitaciones de tiempo en el desarrollo del trabajo, y de acuerdo con las recomendaciones del personal de ACSL, la evaluación del comportamiento del algoritmo se llevó a cabo bajo la presencia de la preferencia descrita anteriormente.

En general, los principales comportamientos defectuosos observados en los resultados de la evaluación de la solución fueron causados por las consecuencias del sobre-ajuste del modelo durante el refinamiento fino de la política estudiante. Se concluyó que la generación adecuada de la base de datos de trayectorias para el refinamiento fino es crucial para que el rendimiento y la capacidad de generalización del algoritmo sean aceptables. 

Se logró implementar una solución que permite a un QUAV evadir obstáculos de forma independiente sin proporcionar anteriormente información sobre su entorno, y que además se puede ejecutar a tiempo real sobre un hardware ligero y con recursos limitados. Sin mencionar que la totalidad de la solución trabaja en concordancia y sobre el marco de trabajo de ACSL, permitiendo una integración automática con el ecosistema de aplicaciones de los vehículos de ACSL.

Es importante resaltar los beneficios obtenidos para ACSL dentro del marco de la presente investigación; destaca lo complejo que resulta ejecutar aplicaciones con redes neuronales en un sistema embebido, como es el hardware de dron ligero. Se logró ejecutar satisfactoriamente la navegación del dron, apesar de lo sensible que son los algoritmos que utilizan redes neuronales a la calidad de los datos de entrenamiento, habiendo verificado que el método original no genera conjuntos de datos buenos para velocidades relativamente lentas. 

La implementación del algoritmo en SOTEN es de importancia vital para ACSL como base para trabajos futuros. Se demostró que realizando un refinamiento fino adecuado de la política estudiante, se puede tener ya en funcionamiento un algoritmo de evasión de obstáculos que revolucione la autonomía y seguridad de los drones, manteniendo así a ACSL como uno de los líderes mundiales en la innovación y desarrollo de la tecnología de drones.

En este sentido, y para finalizar, se recomienda para futuras investigaciones, asegurarse de que el entorno de simulación utilizado para generar las trayectorias sea adecuado a la rapidez promedio de ejecución \jim{v_{des}}. Es importante que las dimensiones de los obstáculos permitan que en una observación se puedan considerar distintas alternativas para esquivar un mismo obstáculo. Si las alternativas consideradas tienden a alinearse hacia un comportamiento en particular, la política estudiante tendrá una fuerte tendencia a utilizar ese comportamiento incluso en casos cuando resulte riesgoso, tal como sucedió en este trabajo con la preferencia por esquivar hacia el flanco izquierdo. Este comportamiento del dron podría mejorarse en futuras investigaciones si se modifica la configuración de obstáculos, si se incrementa la longitud de las trayectorias generadas o si se utiliza un algoritmo de planificación global diferente, adaptado a velocidades \jim{v_{des}} menores a 3 m/s. En síntesis, lo importante es generar una base de datos de refinamiento fino con nivel de generalización similar al utilizado para el entrenamiento del modelo original.

Se recomienda mejorar la instrumentación del dron para poder tener acceso a las medidas de aceleración y jerk, y de esta manera planificar de mejor forma las trayectorias globales en todos los rangos de velocidades, desde velocidades bajas hasta velocidades altas.